{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Checking for Corrupted Image and Removing them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_train = \"D:/CODING/ML_project/IEEE_Parkinson/image pre proc/dataset/train/African\"\n",
    "dog_train = \"D:/CODING/ML_project/IEEE_Parkinson/image pre proc/dataset/train/Asian\"\n",
    "# cat_train_store = \"/Users/sohomsen/Downloads/dataset/train/African1\"\n",
    "# dog_train_store = \"/Users/sohomsen/Downloads/dataset/train/Asian1\"\n",
    "\n",
    "cat_test = \"D:/CODING/ML_project/IEEE_Parkinson/image pre proc/dataset/test/African\"\n",
    "dog_test = \"D:/CODING/ML_project/IEEE_Parkinson/image pre proc/dataset/test/Asian\"\n",
    "# cat_test_store = \"/Users/sohomsen/Downloads/dataset/test/African1\"\n",
    "# dog_test_store = \"/Users/sohomsen/Downloads/dataset/test/Asian1\"\n",
    "\n",
    "# directory_list_train = [cat_train,dog_train]\n",
    "# directory_list_test = [cat_test,dog_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image1(dir_path):\n",
    "    import os\n",
    "    from PIL import Image\n",
    "\n",
    "    # Specify the directory path that contains the images\n",
    "    # dir_path = 'path/to/directory'\n",
    "\n",
    "    # Iterate over all files in the directory\n",
    "    for filename in os.listdir(dir_path):\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "\n",
    "        # Check if the file is an image file\n",
    "        if not file_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            # Open the image and check if it is corrupted\n",
    "            with Image.open(file_path) as img:\n",
    "                img.verify()\n",
    "\n",
    "        except (IOError, SyntaxError) as e:\n",
    "            # Delete the corrupted image and print a message\n",
    "            os.remove(file_path)\n",
    "            print(f\"{filename} has been deleted because it is corrupted.\")\n",
    "\n",
    "            continue\n",
    "\n",
    "        # Print a message for the valid image\n",
    "        # print(f\"{filename} is a valid image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_image(paths,flag):\n",
    "    import os\n",
    "    from PIL import Image\n",
    "    newFolder_path = \"/Users/sohomsen/Downloads/dataset\"+\"/\"+flag\n",
    "    os.mkdir(newFolder_path)\n",
    "    extensions = {'jpg':1,'jpeg':1,'png':1}\n",
    "\n",
    "    for path in paths:\n",
    "        temp = path.split(\"/\")[-1]\n",
    "        files = os.listdir(path)\n",
    "        # newFolder_image = newFolder_path + \"/\" + temp\n",
    "        # print(newFolder_image)\n",
    "        # os.mkdir(newFolder_image)\n",
    "        for file in files:\n",
    "            ext = file.split(\".\")[-1]\n",
    "            # print(ext)\n",
    "            if ext in extensions:\n",
    "                try:\n",
    "                    with Image.open(path+\"/\"+file) as img:\n",
    "                        img.verify()\n",
    "                        im = Image.open(path+\"/\"+file)\n",
    "                        # im_resized = im.resize((1000,1000))\n",
    "                        # filepath = f\"{newFolder_image}/{file}.jpg\"\n",
    "                        # im_resized.save(filepath)\n",
    "                except (IOError, SyntaxError) as e:\n",
    "                    os.remove(path+\"/\"+file) # remove the corrupted file\n",
    "                    print(str(file)+\" : The image file is corrupted and has been removed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_image1(cat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_image1(cat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_image(directory_list_test,\"test1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_image(directory_list_train,\"train1\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>AUC-ROC and AUC-PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AUC_ROC_generator(y_test, y_pred,model_name):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    auc_roc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure(dpi=100)\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC={auc_roc:.3f}')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curve for '+model_name)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def AUC_PR_generator(y_test, y_pred,model_name):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import precision_recall_curve, average_precision_score,auc\n",
    "    precision,recall,thresholds=precision_recall_curve(y_test, y_pred)\n",
    "    avg_precision=average_precision_score(y_test, y_pred)\n",
    "    pr_auc=auc(recall,precision)\n",
    "    plt.figure(dpi=100)\n",
    "    plt.plot(recall,precision,lw=1,color='red',label=f'AP={avg_precision:.3f};AUC={pr_auc:.3f}')\n",
    "    plt.fill_between(recall,precision,-1,facecolor='y',alpha=0.5)\n",
    "    plt.title('PR Curve for '+model_name)\n",
    "    plt.xlabel('Recall(TPR)')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.xlim([-0.05,1.05])\n",
    "    plt.ylim([-0.05,1.05])\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Model():\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "    from sklearn.metrics import classification_report\n",
    "    from PIL import Image\n",
    "\n",
    "    cnn = tf.keras.models.Sequential()\n",
    "\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "    training_set = train_datagen.flow_from_directory('/Users/sohomsen/Desktop/DataScience/Classification/ImageClassification/WasteClassification/untitled folder/train', target_size=(64,64), batch_size=32,class_mode='binary')\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_set = test_datagen.flow_from_directory('/Users/sohomsen/Desktop/DataScience/Classification/ImageClassification/WasteClassification/untitled folder/val', target_size=(64,64), batch_size=32,class_mode='binary')\n",
    "\n",
    "    hidden_layer = int(input(\"Enter number of hidden layers you want : \"))\n",
    "    cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu',input_shape=[64,64,3]))\n",
    "    cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "\n",
    "    for _ in range(hidden_layer-1):\n",
    "        cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "        cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
    "    \n",
    "    cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    cnn.add(tf.keras.layers.Dense(units=128, activation=\"relu\"))\n",
    "    cnn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    cnn.fit(x = training_set, validation_data = test_set, epochs = 10)\n",
    "\n",
    "    probs = cnn.predict(test_set)\n",
    "    print(probs)\n",
    "\n",
    "    # predict_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    # test_image = predict_datagen.apply_transform(\"/Users/sohomsen/Downloads/dataset/test/test/African1/af_te1.jpg.jpg\")\n",
    "\n",
    "    # #img = Image.open(\"/Users/sohomsen/Downloads/dataset/test/test/African1/af_te1.jpg.jpg\")\n",
    "    # preds = cnn.predict(test_image)\n",
    "    # print(\"Predicted : \",preds)\n",
    "\n",
    "    model_name = \"CNN\"\n",
    "    AUC_ROC_generator(test_set.classes,probs,model_name)\n",
    "    \n",
    "    return probs, test_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22564 images belonging to 2 classes.\n",
      "Found 2513 images belonging to 2 classes.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x28fdd44c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_train_function.<locals>.train_function at 0x28fdd44c0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "705/706 [============================>.] - ETA: 0s - loss: 0.4902 - accuracy: 0.7649WARNING:tensorflow:AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x28fd6d9d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_test_function.<locals>.test_function at 0x28fd6d9d0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "706/706 [==============================] - 27s 38ms/step - loss: 0.4901 - accuracy: 0.7650 - val_loss: 0.3362 - val_accuracy: 0.8675\n",
      "Epoch 2/10\n",
      "706/706 [==============================] - 25s 35ms/step - loss: 0.4108 - accuracy: 0.8199 - val_loss: 0.3821 - val_accuracy: 0.8460\n",
      "Epoch 3/10\n",
      "706/706 [==============================] - 24s 34ms/step - loss: 0.3747 - accuracy: 0.8380 - val_loss: 0.2942 - val_accuracy: 0.8945\n",
      "Epoch 4/10\n",
      "706/706 [==============================] - 23s 33ms/step - loss: 0.3594 - accuracy: 0.8492 - val_loss: 0.3507 - val_accuracy: 0.8504\n",
      "Epoch 5/10\n",
      "706/706 [==============================] - 24s 33ms/step - loss: 0.3518 - accuracy: 0.8532 - val_loss: 0.2873 - val_accuracy: 0.8926\n",
      "Epoch 6/10\n",
      "706/706 [==============================] - 27s 38ms/step - loss: 0.3355 - accuracy: 0.8558 - val_loss: 0.3267 - val_accuracy: 0.8671\n",
      "Epoch 7/10\n",
      "706/706 [==============================] - 26s 37ms/step - loss: 0.3319 - accuracy: 0.8621 - val_loss: 0.2927 - val_accuracy: 0.8886\n",
      "Epoch 8/10\n",
      "706/706 [==============================] - 26s 37ms/step - loss: 0.3144 - accuracy: 0.8699 - val_loss: 0.2744 - val_accuracy: 0.8977\n",
      "Epoch 9/10\n",
      "706/706 [==============================] - 27s 38ms/step - loss: 0.3107 - accuracy: 0.8727 - val_loss: 0.2559 - val_accuracy: 0.9033\n",
      "Epoch 10/10\n",
      "706/706 [==============================] - 27s 38ms/step - loss: 0.3127 - accuracy: 0.8686 - val_loss: 0.2907 - val_accuracy: 0.8770\n",
      "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x28ca4d160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x28ca4d160> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: unsupported operand type(s) for -: 'NoneType' and 'int'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "[[0.8219308 ]\n",
      " [0.00192265]\n",
      " [0.03952665]\n",
      " ...\n",
      " [0.21050061]\n",
      " [0.6958967 ]\n",
      " [0.03997799]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "probs, test_set = CNN_Model()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><b>CNN using PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loading Done\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x16384 and 4096x4096)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/n0/g9swhc_n03v4z573dcpb_42w0000gn/T/ipykernel_3502/2061094075.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# Forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# Compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/TF3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/n0/g9swhc_n03v4z573dcpb_42w0000gn/T/ipykernel_3502/2061094075.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;31m# Apply hidden layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/TF3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/TF3/lib/python3.8/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x16384 and 4096x4096)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the CNN model\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_hidden_layers):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        # Create hidden layers based on user input\n",
    "        self.hidden_layers = nn.ModuleList()\n",
    "        for i in range(num_hidden_layers):\n",
    "            self.hidden_layers.append(nn.Linear(64 * 8 * 8, 64 * 8 * 8))\n",
    "            self.hidden_layers.append(nn.ReLU(inplace=True))\n",
    "        \n",
    "        self.fc = nn.Linear(64 * 8 * 8, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        \n",
    "        x = self.maxpool(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        # Apply hidden layers\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "################################### DATASET LOADING #################################\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "# Define the path to the directory containing the user's images\n",
    "train_dir = '/Users/sohomsen/Desktop/DataScience/Classification/ImageClassification/WasteClassification/untitled folder/train'\n",
    "test_dir = '/Users/sohomsen/Desktop/DataScience/Classification/ImageClassification/WasteClassification/untitled folder/val'\n",
    "\n",
    "# Define transforms to normalize the data\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),    # resize the images to 32x32\n",
    "    transforms.ToTensor(),          # convert the images to PyTorch tensors\n",
    "    transforms.Normalize((0.5,), (0.5,))  # normalize the images\n",
    "])\n",
    "\n",
    "# Create an ImageFolder dataset using the user's data directory and the transforms\n",
    "train_dataset = ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "# Create a DataLoader to provide batches of training data\n",
    "batch_size = 64  # the size of each batch\n",
    "shuffle = True   # whether to shuffle the data\n",
    "num_workers = 2  # the number of worker processes for parallel data loading\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "print(\"Dataset Loading Done\")\n",
    "##################################### DATASET DONE ###################################\n",
    "\n",
    "# Define the CNN model\n",
    "num_classes = 2              # the number of output classes\n",
    "num_hidden_layers = 4    # the number of hidden layers specified by the user\n",
    "model = CNN(num_hidden_layers)                  # define the CNN model with the specified number of hidden layers\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train the model using the dataloader\n",
    "for epoch in range(10):\n",
    "    for inputs, targets in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update model parameters\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    # Test the model using the testing data\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        for inputs, targets in test_loader:\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            # Compute predictions\n",
    "            _, predicted = torch.max(outputs, dim=1)\n",
    "            \n",
    "            # Compute number of correct predictions\n",
    "            total_correct += (predicted == targets).sum().item()\n",
    "            total_samples += targets.size(0)\n",
    "        \n",
    "        # Compute accuracy\n",
    "        accuracy = total_correct / total_samples\n",
    "        print('Epoch {}, Test accuracy: {:.2f}%'.format(epoch, accuracy * 100))\n",
    "        \n",
    "    model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
